{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/home/mingi/data/vistext/data/simple_images/horizontal\"\n",
    "tsv_folder = \"/home/mingi/data/vistext/data/test_tsv\"\n",
    "save_file = \"/home/mingi/data/chartgemma/one_by_one_results/horizontal.jsonl\"\n",
    "\n",
    "model_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_folder, tsv_folder, processor):\n",
    "        self.image_folder = image_folder\n",
    "        self.processor = processor\n",
    "        self.tsv_folder = tsv_folder\n",
    "        self.file_names = os.listdir(image_folder)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # prepare all questions for one file\n",
    "        image_file = self.file_names[index]\n",
    "        tsv_file = image_file.split(\".\")[0] + \".tsv\"\n",
    "\n",
    "        image = Image.open(os.path.join(self.image_folder, image_file)).convert(\"RGB\")\n",
    "        tsv = pd.read_csv(os.path.join(self.tsv_folder, tsv_file), sep=\"\\t\")\n",
    "\n",
    "        question_list = []\n",
    "        value_list = []\n",
    "        for row in tsv.itertuples(index=False, name=None):\n",
    "            row = list(row)\n",
    "            question = f\"What is the value of {row[0]}?\\nAnswer the question using only number.\"\n",
    "            question_list.append(question)\n",
    "            value_list.append(row[1])\n",
    "\n",
    "        inputs = []\n",
    "        prompt_lengths = []\n",
    "        for question in question_list:\n",
    "            input = self.processor(text=question, images=image, return_tensors=\"pt\")\n",
    "            input = {k: v.to(\"cuda\") for k, v in input.items()}\n",
    "            inputs.append(input)\n",
    "\n",
    "            prompt_length = input[\"input_ids\"].shape[1]\n",
    "            prompt_lengths.append(prompt_length)\n",
    "\n",
    "        return inputs, prompt_lengths, image_file, value_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, prompt_lengths, image_file, value_list = zip(*batch)\n",
    "\n",
    "    return inputs, prompt_lengths, image_file, value_list\n",
    "\n",
    "\n",
    "def create_data_loader(\n",
    "    image_folder,\n",
    "    tsv_folder,\n",
    "    processor,\n",
    "    batch_size=1,\n",
    "    # num_workers=4,\n",
    "):\n",
    "    assert batch_size == 1, \"batch_size must be 1\"\n",
    "    dataset = CustomDataset(image_folder, tsv_folder, processor)\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        # num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mingi/anaconda3/envs/tinyllava_factory/lib/python3.10/site-packages/transformers/models/paligemma/configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af16edb929ee4eca9d095059f4bc3dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model_path == None:\n",
    "    model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "        \"ahmed-masry/chartgemma\", torch_dtype=torch.float16\n",
    "    ).cuda()\n",
    "else:\n",
    "    model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "        model_path, torch_dtype=torch.float16\n",
    "    ).cuda()\n",
    "processor = AutoProcessor.from_pretrained(\"ahmed-masry/chartgemma\")\n",
    "\n",
    "os.makedirs(os.path.dirname(save_file), exist_ok=True)\n",
    "ans_file = open(save_file, \"w\")\n",
    "\n",
    "data_loader = create_data_loader(\n",
    "    image_folder=image_folder, tsv_folder=tsv_folder, processor=processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 8/373 [01:46<1:11:57, 11.83s/it]"
     ]
    }
   ],
   "source": [
    "for inputs, prompt_lengths, image_file, value_list in tqdm(\n",
    "    data_loader, total=len(os.listdir(image_folder))\n",
    "):\n",
    "    inputs = inputs[0]\n",
    "    image_file = image_file[0]\n",
    "    prompt_lengths = prompt_lengths[0]\n",
    "    value_list = value_list[0]\n",
    "\n",
    "    output_text_list = []\n",
    "\n",
    "    for input, prompt_length in zip(inputs, prompt_lengths):\n",
    "        with torch.inference_mode():\n",
    "            generate_ids = model.generate(**input, num_beams=4, max_new_tokens=512)\n",
    "\n",
    "        output_text = processor.batch_decode(\n",
    "            generate_ids[:, prompt_length:],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False,\n",
    "        )[0]\n",
    "        output_text_list.append(output_text)\n",
    "\n",
    "        # print(output_text)\n",
    "\n",
    "    ans_file.write(\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"image_file\": image_file,\n",
    "                \"text\": output_text_list,\n",
    "                \"value_list\": value_list,\n",
    "            }\n",
    "        )\n",
    "        + \"\\n\"\n",
    "    )\n",
    "ans_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyllava_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
